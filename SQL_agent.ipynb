{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Hi,\n",
        "# What do you want to do for the final project? Any ideas? I'm happy to connect..\n",
        "# https://www.linkedin.com/in/viviankaun/\n"
      ],
      "metadata": {
        "id": "B7t-JbxXXg1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community pypdf langchain-openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "open_ai_key = userdata.get('open_ai_key')\n",
        "client = OpenAI(api_key=open_ai_key)\n"
      ],
      "metadata": {
        "id": "6SV9ayYc_wK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4c8d90-c6cd-4099-ec06-8f0dd989b449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.9 (from langchain-community)\n",
            "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.23 (from langchain-community)\n",
            "  Downloading langchain_core-0.2.23-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
            "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Collecting openai<2.0.0,>=1.32.0 (from langchain-openai)\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.9->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (2.8.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.23->langchain-community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.32.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain-community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.2.11-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.23-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.11 langchain-community-0.2.10 langchain-core-0.2.23 langchain-openai-0.1.17 langchain-text-splitters-0.2.2 langsmith-0.1.93 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.37.1 orjson-3.10.6 pypdf-4.3.1 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C0GYUOMh_VNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a0f2e4-4b35-42fb-d152-88b1f00a1f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-26 06:00:08--  https://www.accenture.com/content/dam/accenture/final/accenture-com/document-2/Accenture-Life-Trends-2024-Full-Report.pdf\n",
            "Resolving www.accenture.com (www.accenture.com)... 108.138.64.112, 108.138.64.78, 108.138.64.84, ...\n",
            "Connecting to www.accenture.com (www.accenture.com)|108.138.64.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30934749 (30M) [application/pdf]\n",
            "Saving to: ‘Accenture-Life-Trends-2024-Full-Report.pdf’\n",
            "\n",
            "Accenture-Life-Tren 100%[===================>]  29.50M  47.7MB/s    in 0.6s    \n",
            "\n",
            "2024-07-26 06:00:09 (47.7 MB/s) - ‘Accenture-Life-Trends-2024-Full-Report.pdf’ saved [30934749/30934749]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget \"https://www.accenture.com/content/dam/accenture/final/accenture-com/document-2/Accenture-Life-Trends-2024-Full-Report.pdf\"\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader('Accenture-Life-Trends-2024-Full-Report.pdf')\n",
        "pages = loader.load_and_split()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#langchain.chains.combine_documents.stuff"
      ],
      "metadata": {
        "id": "3wwqLynaJbUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Define prompt\n",
        "prompt_template = \"\"\"Write a concise summary in a maximum of 10 bullet points of the following text enclosed within three backticks.:\n",
        "```{text}```\n",
        "CONCISE SUMMARY:\"\"\"\n",
        "prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "# Define LLM chain\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", api_key=open_ai_key)\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Define StuffDocumentsChain\n",
        "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
        "\n",
        "res = stuff_chain.invoke(pages[1:56])\n",
        "res[\"output_text\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "k5wDZ22BADCu",
        "outputId": "fdd4e7fb-0532-471e-976c-0c15cc15e9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'- Accenture Song creates annual trends to explore the interplay between people and their behaviors, focusing on customer-obsession as a growth strategy.\\n- Trends examine shifts in customer behavior and aim to help businesses stay relevant to customers.\\n- The Accenture Life Trends 2024 report delves into various layers that influence how people live their lives.\\n- It highlights the fragility in relationships between people and societal influences, leading to a state of flux in society.\\n- The report discusses Trend 1, \"Where\\'s the love?\", which focuses on the impact of cuts on customer obsession and customer experiences.\\n- It also covers Trend 2, \"The great interface shift\", which explores how generative AI is upgrading the internet experience.\\n- Trend 3, \"Meh-diocrity\", discusses the challenges of creativity being hindered'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# from langchain.chains.combine_documents.map_reduce"
      ],
      "metadata": {
        "id": "qENPt24mOdPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\n",
        "\n",
        "# Define MapReduceDocumentsChain prompts\n",
        "map_prompt_template = \"\"\"write a concise summary in a maximum of 10 bullet points of the following text enclosed within three backticks.\n",
        "```{text}```\n",
        "CONCISE SUMMARY:\"\"\"\n",
        "map_prompt = PromptTemplate.from_template(map_prompt_template)\n",
        "\n",
        "reduce_prompt_template = \"\"\"Combine the following summaries into a single concise summary:\n",
        "```{text}```\n",
        "FINAL SUMMARY:\"\"\"\n",
        "reduce_prompt = PromptTemplate.from_template(reduce_prompt_template)\n",
        "\n",
        "# Define LLM for MapReduceDocumentsChain\n",
        "map_llm_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "reduce_llm_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "\n",
        "# Define LLM for MapReduceDocumentsChain\n",
        "map_llm_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "reduce_llm_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
        "\n",
        "# Define a StuffDocumentsChain to use as the reduce_documents_chain for MapReduce\n",
        "reduce_stuff_chain = StuffDocumentsChain(llm_chain=reduce_llm_chain, document_variable_name=\"text\")\n",
        "\n",
        "# Define MapReduceDocumentsChain\n",
        "map_reduce_chain = MapReduceDocumentsChain(\n",
        "    llm_chain=map_llm_chain,\n",
        "    reduce_documents_chain=reduce_stuff_chain,\n",
        "    document_variable_name=\"text\"\n",
        ")\n",
        "\n",
        "# Invoke MapReduceDocumentsChain\n",
        "res_map_reduce = map_reduce_chain.invoke(pages[1:56])\n",
        "res_map_reduce[\"output_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "TyOQWTPWKdQM",
        "outputId": "329a22b8-dde6-424c-e913-de19fce4daac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Accenture Life Trends 2024 explores the evolving relationship between people and technology, challenging traditional norms and milestones. The trends highlight the need for brands to prioritize customer relationships, adapt to changing societal values, and embrace sustainability. The text discusses themes such as mediocrity, the decade of deconstruction, the great interface shift, and the importance of love in technology and brand interactions. Error 429: Human request limit reached indicates the overwhelming pace of change and the need for more efficient communication.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Findings: Map-Rduce spent 1 mins to response, but StuffDocumentsChain spent 4 sec to resposne.\n"
      ],
      "metadata": {
        "id": "2AyCciIEBVZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "# Step 1: Connect to the database or create it if it doesn't exist\n",
        "conn = sqlite3.connect('./sql_lite_database7.db')\n",
        "\n",
        "#Step 2: Create a cursor\n",
        "cursor = conn.cursor()\n",
        "query =  \"\"\"\n",
        "                        CREATE TABLE IF NOT EXISTS \"ORDERS\"\n",
        "                        (\n",
        "                            \"ORD_NUM\" NUMBER(6,0) NOT NULL PRIMARY KEY,\n",
        "                            \"ORD_AMOUNT\" NUMBER(12,2) NOT NULL,\n",
        "                            \"ADVANCE_AMOUNT\" NUMBER(12,2) NOT NULL,\n",
        "                            \"ORD_DATE\" DATE NOT NULL,\n",
        "                            \"CUST_CODE\" VARCHAR2(6) NOT NULL  ,\n",
        "                            \"AGENT_CODE\" CHAR(6) NOT NULL  ,\n",
        "                            \"ORD_DESCRIPTION\" VARCHAR2(60) NOT NULL\n",
        "                        ); \"\"\"\n",
        "cursor.execute(query)\n",
        "query =  \"\"\"\n",
        "INSERT INTO ORDERS VALUES('200100', '1000.00', '600.00', '2008-08-01', 'C00013', 'A003', 'SOD');\n",
        "INSERT INTO ORDERS VALUES('200117', '800.00', '200.00', '2008-10-20', 'C00014', 'A001', 'SOD');\n",
        "INSERT INTO ORDERS VALUES('200123', '500.00', '100.00', '2008-09-16', 'C00022', 'A002', 'SOD');\n",
        "INSERT INTO ORDERS VALUES('200124', '500.00', '100.00', '2008-09-16', 'C00022', 'A004', 'SOD');\n",
        "\"\"\"\n",
        "for row in query.splitlines():\n",
        "    try:\n",
        "        cursor.execute(row)\n",
        "    except:\n",
        "        print(f\"An error occurred\")\n",
        "        print(row)\n",
        "#Step 3: Close the cursor and connection\n",
        "cursor.close()\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "BibdPtFcu9Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utilized SQL Agent to answer user questions by retrieving relevant data from the database. plus few-shot"
      ],
      "metadata": {
        "id": "MxwkSmpWVkaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.agents import create_sql_agent\n",
        "\n",
        "# define the database we want to use for our test\n",
        "db = SQLDatabase.from_uri('sqlite:///sql_lite_database7.db')\n",
        "\n",
        "# choose llm model, in this case the default OpenAI model\n",
        "llm = OpenAI(\n",
        "            temperature=0,\n",
        "            verbose=True,\n",
        "            openai_api_key=open_ai_key\n",
        "            )\n",
        "# setup agent\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors= True,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "CxFDdEkhz-Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQgKbui0oONN",
        "outputId": "98de3d68-cbca-4f8f-c2e1-0e31496cf13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 30228\n",
            "-rw-r--r-- 1 root root 30934749 Oct 18  2023 Accenture-Life-Trends-2024-Full-Report.pdf\n",
            "drwxr-xr-x 1 root root     4096 Jul 24 13:22 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root    12288 Jul 26 06:01 sql_lite_database7.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = input(\"Please enter your question: \")\n",
        "agent_executor.invoke(question)"
      ],
      "metadata": {
        "id": "9dAfhU8CLVJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327a22fc-5fcb-4fd3-b511-23a08f4883c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your question: How many orders do we have ?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mORDERS\u001b[0m\u001b[32;1m\u001b[1;3m I should query the ORDERS table to get the number of orders.\n",
            "Action: sql_db_schema\n",
            "Action Input: ORDERS\u001b[0m\u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE \"ORDERS\" (\n",
            "\t\"ORD_NUM\" NUMERIC(6, 0) NOT NULL, \n",
            "\t\"ORD_AMOUNT\" NUMERIC(12, 2) NOT NULL, \n",
            "\t\"ADVANCE_AMOUNT\" NUMERIC(12, 2) NOT NULL, \n",
            "\t\"ORD_DATE\" DATE NOT NULL, \n",
            "\t\"CUST_CODE\" TEXT(6) NOT NULL, \n",
            "\t\"AGENT_CODE\" CHAR(6) NOT NULL, \n",
            "\t\"ORD_DESCRIPTION\" TEXT(60) NOT NULL, \n",
            "\tPRIMARY KEY (\"ORD_NUM\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from ORDERS table:\n",
            "ORD_NUM\tORD_AMOUNT\tADVANCE_AMOUNT\tORD_DATE\tCUST_CODE\tAGENT_CODE\tORD_DESCRIPTION\n",
            "200100\t1000.00\t600.00\t2008-08-01\tC00013\tA003\tSOD\n",
            "200117\t800.00\t200.00\t2008-10-20\tC00014\tA001\tSOD\n",
            "200123\t500.00\t100.00\t2008-09-16\tC00022\tA002\tSOD\n",
            "*/\u001b[0m\u001b[32;1m\u001b[1;3m I should query the ORDERS table and count the number of rows.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT COUNT(*) FROM ORDERS\u001b[0m\u001b[36;1m\u001b[1;3m[(4,)]\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 4\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'How many orders do we have ?', 'output': '4'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "few_shot_examples = \"\"\"\n",
        "Q: How many customers do we have in our database?\n",
        "A: We currently have 4 customers in our database.\n",
        "\n",
        "Q: What is the total revenue generated the year 2008)?\n",
        "A: The total revenue generated this year is $2800,000, ORD_DATE>='2008-01-01' AND ORD_DATE<='2008-12-31'\n",
        "\n",
        "Q: Please provide a detailed response to the following question: {question}\n",
        "\"\"\"\n",
        "\n",
        "# Define the user's question\n",
        "question = input(\"Please enter your question: \")\n",
        "few_shot_prompt = few_shot_examples.format(question=question)\n",
        "agent_executor.invoke(few_shot_prompt)"
      ],
      "metadata": {
        "id": "T-aUa14PCHtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c47e26d-c356-4bae-a000-201f97e03d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your question: What is the highest revenue in a day?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\u001b[38;5;200m\u001b[1;3mORDERS\u001b[0m\u001b[32;1m\u001b[1;3m I should query the ORDERS table to see what columns I can use to find the highest revenue in a day.\n",
            "Action: sql_db_schema\n",
            "Action Input: ORDERS\u001b[0m\u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE \"ORDERS\" (\n",
            "\t\"ORD_NUM\" NUMERIC(6, 0) NOT NULL, \n",
            "\t\"ORD_AMOUNT\" NUMERIC(12, 2) NOT NULL, \n",
            "\t\"ADVANCE_AMOUNT\" NUMERIC(12, 2) NOT NULL, \n",
            "\t\"ORD_DATE\" DATE NOT NULL, \n",
            "\t\"CUST_CODE\" TEXT(6) NOT NULL, \n",
            "\t\"AGENT_CODE\" CHAR(6) NOT NULL, \n",
            "\t\"ORD_DESCRIPTION\" TEXT(60) NOT NULL, \n",
            "\tPRIMARY KEY (\"ORD_NUM\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from ORDERS table:\n",
            "ORD_NUM\tORD_AMOUNT\tADVANCE_AMOUNT\tORD_DATE\tCUST_CODE\tAGENT_CODE\tORD_DESCRIPTION\n",
            "200100\t1000.00\t600.00\t2008-08-01\tC00013\tA003\tSOD\n",
            "200117\t800.00\t200.00\t2008-10-20\tC00014\tA001\tSOD\n",
            "200123\t500.00\t100.00\t2008-09-16\tC00022\tA002\tSOD\n",
            "*/\u001b[0m\u001b[32;1m\u001b[1;3m I should query the ORDERS table and use the MAX function to find the highest revenue in a day.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT MAX(ORD_AMOUNT) FROM ORDERS\u001b[0m\u001b[36;1m\u001b[1;3m[(1000,)]\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The highest revenue in a day is $1000.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"\\nQ: How many customers do we have in our database?\\nA: We currently have 4 customers in our database.\\n\\nQ: What is the total revenue generated the year 2008)?\\nA: The total revenue generated this year is $2800,000, ORD_DATE>='2008-01-01' AND ORD_DATE<='2008-12-31'\\n\\nQ: Please provide a detailed response to the following question: What is the highest revenue in a day?\\n\",\n",
              " 'output': 'The highest revenue in a day is $1000.'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ar68zqvPL3wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = input(\"Please enter your question: \")\n",
        "agent_executor.invoke(question)"
      ],
      "metadata": {
        "id": "UHuv-PiaHz7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4fc0c7-bccb-4977-fd20-521d3a8a478b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your question:  What is highest revenue we earned in single day?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\u001b[38;5;200m\u001b[1;3mORDERS\u001b[0m\u001b[32;1m\u001b[1;3mI should query the ORDERS table to find the highest revenue earned in a single day.\n",
            "Action: sql_db_schema\n",
            "Action Input: ORDERS\u001b[0m\u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE \"ORDERS\" (\n",
            "\t\"ORD_NUM\" NUMERIC(6, 0) NOT NULL, \n",
            "\t\"ORD_AMOUNT\" NUMERIC(12, 2) NOT NULL, \n",
            "\t\"ADVANCE_AMOUNT\" NUMERIC(12, 2) NOT NULL, \n",
            "\t\"ORD_DATE\" DATE NOT NULL, \n",
            "\t\"CUST_CODE\" TEXT(6) NOT NULL, \n",
            "\t\"AGENT_CODE\" CHAR(6) NOT NULL, \n",
            "\t\"ORD_DESCRIPTION\" TEXT(60) NOT NULL, \n",
            "\tPRIMARY KEY (\"ORD_NUM\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from ORDERS table:\n",
            "ORD_NUM\tORD_AMOUNT\tADVANCE_AMOUNT\tORD_DATE\tCUST_CODE\tAGENT_CODE\tORD_DESCRIPTION\n",
            "200100\t1000.00\t600.00\t2008-08-01\tC00013\tA003\tSOD\n",
            "200117\t800.00\t200.00\t2008-10-20\tC00014\tA001\tSOD\n",
            "200123\t500.00\t100.00\t2008-09-16\tC00022\tA002\tSOD\n",
            "*/\u001b[0m\u001b[32;1m\u001b[1;3m I should query the ORDERS table for the highest revenue earned in a single day by ordering the results by ORD_AMOUNT in descending order and limiting the results to 1.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT ORD_AMOUNT FROM ORDERS ORDER BY ORD_AMOUNT DESC LIMIT 1\u001b[0m\u001b[36;1m\u001b[1;3m[(1000,)]\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The highest revenue earned in a single day is $1000.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': ' What is highest revenue we earned in single day?',\n",
              " 'output': 'The highest revenue earned in a single day is $1000.'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}